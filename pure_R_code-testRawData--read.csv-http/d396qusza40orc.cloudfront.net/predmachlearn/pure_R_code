> testRawData<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
> trainRawData<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
> testRawData <- testRawData[, colSums(is.na(trainRawData)) == 0]
> trainRawData <- trainRawData[, colSums(is.na(trainRawData)) == 0]
> trainRawData <- trainRawData[, colSums(is.na(testRawData)) == 0]
> testRawData <- testRawData[, colSums(is.na(testRawData)) == 0]
> dim(trainRawData)
[1] 19622    60
> dim(testRawData)
[1] 20 60
> names(trainRawData)
 [1] "X"                    "user_name"            "raw_timestamp_part_1"
 [4] "raw_timestamp_part_2" "cvtd_timestamp"       "new_window"          
 [7] "num_window"           "roll_belt"            "pitch_belt"          
[10] "yaw_belt"             "total_accel_belt"     "gyros_belt_x"        
[13] "gyros_belt_y"         "gyros_belt_z"         "accel_belt_x"        
[16] "accel_belt_y"         "accel_belt_z"         "magnet_belt_x"       
[19] "magnet_belt_y"        "magnet_belt_z"        "roll_arm"            
[22] "pitch_arm"            "yaw_arm"              "total_accel_arm"     
[25] "gyros_arm_x"          "gyros_arm_y"          "gyros_arm_z"         
[28] "accel_arm_x"          "accel_arm_y"          "accel_arm_z"         
[31] "magnet_arm_x"         "magnet_arm_y"         "magnet_arm_z"        
[34] "roll_dumbbell"        "pitch_dumbbell"       "yaw_dumbbell"        
[37] "total_accel_dumbbell" "gyros_dumbbell_x"     "gyros_dumbbell_y"    
[40] "gyros_dumbbell_z"     "accel_dumbbell_x"     "accel_dumbbell_y"    
[43] "accel_dumbbell_z"     "magnet_dumbbell_x"    "magnet_dumbbell_y"   
[46] "magnet_dumbbell_z"    "roll_forearm"         "pitch_forearm"       
[49] "yaw_forearm"          "total_accel_forearm"  "gyros_forearm_x"     
[52] "gyros_forearm_y"      "gyros_forearm_z"      "accel_forearm_x"     
[55] "accel_forearm_y"      "accel_forearm_z"      "magnet_forearm_x"    
[58] "magnet_forearm_y"     "magnet_forearm_z"     "classe"           
> new<-testRawData[,-1]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> testRawData<-new
> new<-trainRawData[,-1]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> new<-new[,-2]
> trainRawData<-new
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Find out what's changed in ggplot2 with
news(Version == "1.0.1", package = "ggplot2")
> set.seed(12345)
> inTrain<-createDataPartition(y=trainRawData$classe, p=0.7, list=FALSE)
> 
> training<-trainRawData[inTrain,]
> testing<-trainRawData[-inTrain,]
> controlRf <- trainControl(method="cv", 5)
> modRF<-train(classe~., data=training, method="rf",ntree=250,trControl=controlRf)
> modRF
Random Forest 

13737 samples
   53 predictor
    5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 10989, 10990, 10988, 10990, 10991 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
   2    0.9906828  0.9882130  0.002335447  0.002955031
  29    0.9903185  0.9877537  0.001466699  0.001856144
  57    0.9856586  0.9818574  0.002089468  0.002645576

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 2. 
> pred<-predict(modRF,testing)
> table(pred,testing$classe)
    
pred    A    B    C    D    E
   A 1673   15    0    0    0
   B    1 1118   14    0    0
   C    0    6 1008   25    0
   D    0    0    4  939    4
   E    0    0    0    0 1078
> print(predict(modRF, newdata=testRawData))
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
> answer<-print(predict(modRF, newdata=testRawData))
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
> source('~/Dropbox/MFE Courses/Machine Learning/Week3/project/pml_write_files.R')
> pml_write_files(answer)
